{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# NFL Big Data Bowl 2026 - Integrated Submission\n",
                "\n",
                "This notebook implements the full inference pipeline including:\n",
                "1. **Transformer Backbone** (Time Dimension)\n",
                "2. **GNN Interaction Layer** (Space Dimension)\n",
                "3. **GBDT Model** (Tabular Features)\n",
                "4. **Ensemble Logic**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import warnings\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import polars as pl\n",
                "from pathlib import Path\n",
                "from typing import Dict, List, Tuple, Optional, Union\n",
                "from dataclasses import dataclass, field\n",
                "import pickle\n",
                "import json\n",
                "import glob\n",
                "import sys\n",
                "\n",
                "# Machine Learning\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Deep Learning\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# Graph Neural Networks\n",
                "try:\n",
                "    import torch_geometric\n",
                "    from torch_geometric.nn import GCNConv, GATConv, TransformerConv\n",
                "    from torch_geometric.data import Data, Batch\n",
                "    HAS_TORCH_GEOMETRIC = True\n",
                "except ImportError:\n",
                "    HAS_TORCH_GEOMETRIC = False\n",
                "\n",
                "# Gradient Boosting\n",
                "try:\n",
                "    import lightgbm as lgb\n",
                "    HAS_LIGHTGBM = True\n",
                "except ImportError:\n",
                "    HAS_LIGHTGBM = False\n",
                "\n",
                "try:\n",
                "    import xgboost as xgb\n",
                "    HAS_XGBOOST = True\n",
                "except ImportError:\n",
                "    HAS_XGBOOST = False\n",
                "\n",
                "import kaggle_evaluation.nfl_inference_server\n",
                "\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# Configuration\n",
                "# ============================================================================\n",
                "@dataclass\n",
                "class Config:\n",
                "    \"\"\"Configuration for the NFL Movement Prediction model.\"\"\"\n",
                "    # Data paths\n",
                "    data_dir: str = './train/'\n",
                "    test_dir: str = './test/'\n",
                "    kaggle_data_dir: str = '/kaggle/input/nfl-big-data-bowl-2026-prediction/'\n",
                "    output_dir: str = './outputs/'\n",
                "    \n",
                "    # Model parameters\n",
                "    random_seed: int = 42\n",
                "    \n",
                "    # Feature engineering\n",
                "    use_velocity_features: bool = True\n",
                "    use_acceleration_features: bool = True\n",
                "    use_angle_features: bool = True\n",
                "    use_distance_features: bool = True\n",
                "    use_separation_features: bool = True\n",
                "\n",
                "    # Transformer parameters\n",
                "    d_model: int = 128\n",
                "    n_heads: int = 8\n",
                "    n_encoder_layers: int = 4\n",
                "    dim_feedforward: int = 512\n",
                "    dropout: float = 0.1\n",
                "    max_seq_len: int = 100\n",
                "\n",
                "    # GNN parameters\n",
                "    gnn_hidden_dim: int = 64\n",
                "    gnn_num_layers: int = 3\n",
                "    gnn_heads: int = 4\n",
                "\n",
                "    # Ensemble weights\n",
                "    transformer_weight: float = 0.4\n",
                "    gnn_weight: float = 0.3\n",
                "    gbdt_weight: float = 0.3\n",
                "\n",
                "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "config = Config()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# Feature Engineering\n",
                "# ============================================================================\n",
                "class FootballFeatureEngineer:\n",
                "    \"\"\"Creates football-specific features for player movement prediction.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: Config):\n",
                "        self.config = config\n",
                "        self.scalers = {}\n",
                "        \n",
                "    def compute_velocity_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Compute velocity-based features.\"\"\"\n",
                "        df = df.copy()\n",
                "        \n",
                "        # Use input features (pre-pass state)\n",
                "        s_col = 's_input' if 's_input' in df.columns else 's'\n",
                "        dir_col = 'dir_input' if 'dir_input' in df.columns else 'dir'\n",
                "        \n",
                "        if s_col in df.columns and dir_col in df.columns:\n",
                "            # Velocity components from speed and direction\n",
                "            df['vx'] = df[s_col] * np.cos(np.radians(df[dir_col]))\n",
                "            df['vy'] = df[s_col] * np.sin(np.radians(df[dir_col]))\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def compute_distance_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Compute distance-based features.\"\"\"\n",
                "        df = df.copy()\n",
                "        \n",
                "        # Get position columns\n",
                "        x_col = 'x_input' if 'x_input' in df.columns else 'x'\n",
                "        y_col = 'y_input' if 'y_input' in df.columns else 'y'\n",
                "        \n",
                "        # Distance to ball landing spot\n",
                "        if 'ball_land_x' in df.columns and 'ball_land_y' in df.columns:\n",
                "            df['dist_to_ball_landing'] = np.sqrt(\n",
                "                (df[x_col] - df['ball_land_x'])**2 + \n",
                "                (df[y_col] - df['ball_land_y'])**2\n",
                "            )\n",
                "        \n",
                "        # Distance to line of scrimmage\n",
                "        if 'absolute_yardline_number' in df.columns:\n",
                "            df['dist_from_los'] = df[x_col] - df['absolute_yardline_number']\n",
                "        \n",
                "        # Distance to sidelines (field is 53.3 yards wide)\n",
                "        if y_col in df.columns:\n",
                "            df['dist_to_near_sideline'] = np.minimum(df[y_col], 53.3 - df[y_col])\n",
                "            df['dist_from_center'] = np.abs(df[y_col] - 26.65)\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def compute_angle_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Compute angle-based features.\"\"\"\n",
                "        df = df.copy()\n",
                "        \n",
                "        x_col = 'x_input' if 'x_input' in df.columns else 'x'\n",
                "        y_col = 'y_input' if 'y_input' in df.columns else 'y'\n",
                "        dir_col = 'dir_input' if 'dir_input' in df.columns else 'dir'\n",
                "        o_col = 'o_input' if 'o_input' in df.columns else 'o'\n",
                "        \n",
                "        # Angle to ball landing spot\n",
                "        if 'ball_land_x' in df.columns and 'ball_land_y' in df.columns:\n",
                "            df['angle_to_ball'] = np.degrees(np.arctan2(\n",
                "                df['ball_land_y'] - df[y_col],\n",
                "                df['ball_land_x'] - df[x_col]\n",
                "            ))\n",
                "            \n",
                "            if dir_col in df.columns:\n",
                "                # Difference between direction and angle to ball (pursuit angle)\n",
                "                df['pursuit_angle'] = np.abs(\n",
                "                    ((df[dir_col] - df['angle_to_ball'] + 180) % 360) - 180\n",
                "                )\n",
                "                \n",
                "                # Is player facing the ball? (within 45 degrees)\n",
                "                df['facing_ball'] = (df['pursuit_angle'] < 45).astype(int)\n",
                "        \n",
                "        # Orientation vs direction (body alignment)\n",
                "        if dir_col in df.columns and o_col in df.columns:\n",
                "            df['body_alignment'] = np.abs(\n",
                "                ((df[o_col] - df[dir_col] + 180) % 360) - 180\n",
                "            )\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def compute_player_context_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Compute player-specific context features.\"\"\"\n",
                "        df = df.copy()\n",
                "        \n",
                "        # Encode player side (offense vs defense)\n",
                "        if 'player_side' in df.columns:\n",
                "            df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n",
                "            df['is_defense'] = (df['player_side'] == 'Defense').astype(int)\n",
                "        \n",
                "        # Encode key positions\n",
                "        if 'player_position' in df.columns:\n",
                "            df['is_receiver'] = df['player_position'].isin(['WR', 'TE']).astype(int)\n",
                "            df['is_db'] = df['player_position'].isin(['CB', 'SS', 'FS', 'DB', 'S']).astype(int)\n",
                "            df['is_lb'] = df['player_position'].isin(['LB', 'ILB', 'OLB', 'MLB']).astype(int)\n",
                "        \n",
                "        # Play direction adjustment\n",
                "        if 'play_direction' in df.columns:\n",
                "            df['play_dir_right'] = (df['play_direction'] == 'right').astype(int)\n",
                "        \n",
                "        # Frame-based features\n",
                "        if 'frame_id' in df.columns and 'num_frames_output' in df.columns:\n",
                "            df['frame_progress'] = df['frame_id'] / df['num_frames_output'].clip(lower=1)\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def engineer_features(\n",
                "        self, \n",
                "        df: pd.DataFrame, \n",
                "        is_training: bool = True\n",
                "    ) -> pd.DataFrame:\n",
                "        \"\"\"Apply all feature engineering steps.\"\"\"\n",
                "        \n",
                "        if self.config.use_velocity_features:\n",
                "            df = self.compute_velocity_features(df)\n",
                "        \n",
                "        if self.config.use_distance_features:\n",
                "            df = self.compute_distance_features(df)\n",
                "        \n",
                "        if self.config.use_angle_features:\n",
                "            df = self.compute_angle_features(df)\n",
                "        \n",
                "        df = self.compute_player_context_features(df)\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def get_feature_columns(self) -> List[str]:\n",
                "        \"\"\"Return list of feature column names for model input.\"\"\"\n",
                "        features = [\n",
                "            # Input position/motion features\n",
                "            'x_input', 'y_input', 's_input', 'a_input', 'dir_input', 'o_input',\n",
                "            # Velocity features\n",
                "            'vx', 'vy',\n",
                "            # Distance features\n",
                "            'dist_to_ball_landing', 'dist_from_los',\n",
                "            'dist_to_near_sideline', 'dist_from_center',\n",
                "            # Angle features\n",
                "            'angle_to_ball', 'pursuit_angle', 'facing_ball', 'body_alignment',\n",
                "            # Player context features\n",
                "            'is_offense', 'is_defense', 'is_receiver', 'is_db', 'is_lb',\n",
                "            'play_dir_right', 'frame_progress',\n",
                "            # Ball landing position\n",
                "            'ball_land_x', 'ball_land_y',\n",
                "            # Frame info\n",
                "            'frame_id', 'num_frames_output'\n",
                "        ]\n",
                "        return features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# Deep Learning Models\n",
                "# ============================================================================\n",
                "\n",
                "class PositionalEncoding(nn.Module):\n",
                "    \"\"\"Positional encoding for transformer.\"\"\"\n",
                "    \n",
                "    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n",
                "        super().__init__()\n",
                "        self.dropout = nn.Dropout(p=dropout)\n",
                "        \n",
                "        position = torch.arange(max_len).unsqueeze(1)\n",
                "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
                "        \n",
                "        pe = torch.zeros(max_len, d_model)\n",
                "        pe[:, 0::2] = torch.sin(position * div_term)\n",
                "        pe[:, 1::2] = torch.cos(position * div_term)\n",
                "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
                "        \n",
                "        self.register_buffer('pe', pe)\n",
                "    \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        x = x + self.pe[:, :x.size(1), :]\n",
                "        return self.dropout(x)\n",
                "\n",
                "\n",
                "class PlayerMovementTransformer(nn.Module):\n",
                "    \"\"\"Transformer model for predicting player movement trajectories.\"\"\"\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        input_dim: int,\n",
                "        d_model: int = 128,\n",
                "        n_heads: int = 8,\n",
                "        n_encoder_layers: int = 4,\n",
                "        dim_feedforward: int = 512,\n",
                "        dropout: float = 0.1,\n",
                "        max_seq_len: int = 100\n",
                "    ):\n",
                "        super().__init__()\n",
                "        \n",
                "        self.d_model = d_model\n",
                "        \n",
                "        # Input projection\n",
                "        self.input_proj = nn.Sequential(\n",
                "            nn.Linear(input_dim, d_model),\n",
                "            nn.LayerNorm(d_model),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(dropout)\n",
                "        )\n",
                "        \n",
                "        # Positional encoding\n",
                "        self.pos_encoder = PositionalEncoding(d_model, max_seq_len, dropout)\n",
                "        \n",
                "        # Transformer encoder\n",
                "        encoder_layer = nn.TransformerEncoderLayer(\n",
                "            d_model=d_model,\n",
                "            nhead=n_heads,\n",
                "            dim_feedforward=dim_feedforward,\n",
                "            dropout=dropout,\n",
                "            batch_first=True\n",
                "        )\n",
                "        self.transformer_encoder = nn.TransformerEncoder(\n",
                "            encoder_layer,\n",
                "            num_layers=n_encoder_layers\n",
                "        )\n",
                "        \n",
                "        # Output heads for x and y prediction\n",
                "        self.output_head = nn.Sequential(\n",
                "            nn.Linear(d_model, d_model // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(dropout),\n",
                "            nn.Linear(d_model // 2, 2)  # Predict (x, y)\n",
                "        )\n",
                "    \n",
                "    def forward(\n",
                "        self, \n",
                "        x: torch.Tensor, \n",
                "        mask: Optional[torch.Tensor] = None\n",
                "    ) -> torch.Tensor:\n",
                "        # Project input to model dimension\n",
                "        x = self.input_proj(x)\n",
                "        \n",
                "        # Add positional encoding\n",
                "        x = self.pos_encoder(x)\n",
                "        \n",
                "        # Create attention mask if provided\n",
                "        if mask is not None:\n",
                "            attn_mask = ~mask\n",
                "        else:\n",
                "            attn_mask = None\n",
                "        \n",
                "        # Transformer encoding\n",
                "        encoded = self.transformer_encoder(x, src_key_padding_mask=attn_mask)\n",
                "        \n",
                "        # Predict coordinates (take the last token for prediction in this context)\n",
                "        # Note: In a full sequence model we might predict all steps, but here we predict for the current frame\n",
                "        predictions = self.output_head(encoded[:, -1, :])\n",
                "        \n",
                "        return predictions\n",
                "\n",
                "\n",
                "class PlayerInteractionGNN(nn.Module):\n",
                "    \"\"\"Graph Neural Network for modeling player interactions.\"\"\"\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        input_dim: int,\n",
                "        hidden_dim: int = 64,\n",
                "        output_dim: int = 2,\n",
                "        num_layers: int = 3,\n",
                "        heads: int = 4,\n",
                "        dropout: float = 0.1\n",
                "    ):\n",
                "        super().__init__()\n",
                "        \n",
                "        self.input_dim = input_dim\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.num_layers = num_layers\n",
                "        \n",
                "        # Input projection\n",
                "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
                "        \n",
                "        # GNN layers - use simple MLP-based message passing\n",
                "        self.gnn_layers = nn.ModuleList()\n",
                "        for _ in range(num_layers):\n",
                "            self.gnn_layers.append(nn.Sequential(\n",
                "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
                "                nn.ReLU(),\n",
                "                nn.Dropout(dropout),\n",
                "                nn.Linear(hidden_dim, hidden_dim)\n",
                "            ))\n",
                "        \n",
                "        # Layer normalization\n",
                "        self.layer_norms = nn.ModuleList([\n",
                "            nn.LayerNorm(hidden_dim) for _ in range(num_layers)\n",
                "        ])\n",
                "        \n",
                "        # Output head\n",
                "        self.output_head = nn.Sequential(\n",
                "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(dropout),\n",
                "            nn.Linear(hidden_dim // 2, output_dim)\n",
                "        )\n",
                "        \n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "    \n",
                "    def forward(\n",
                "        self,\n",
                "        x: torch.Tensor,\n",
                "        positions: torch.Tensor,\n",
                "        edge_threshold: float = 15.0\n",
                "    ) -> torch.Tensor:\n",
                "        # Project input\n",
                "        h = self.input_proj(x)\n",
                "        \n",
                "        # Build adjacency based on positions\n",
                "        # x shape: (batch_size, num_nodes, features)\n",
                "        # positions shape: (batch_size, num_nodes, 2)\n",
                "        \n",
                "        diff = positions.unsqueeze(1) - positions.unsqueeze(2) # (B, 1, N, 2) - (B, N, 1, 2) -> (B, N, N, 2)\n",
                "        distances = torch.norm(diff, dim=-1)\n",
                "        adj = (distances < edge_threshold).float()\n",
                "        adj = adj / (adj.sum(dim=-1, keepdim=True) + 1e-8)\n",
                "        \n",
                "        # Message passing layers\n",
                "        for i, layer in enumerate(self.gnn_layers):\n",
                "            neighbor_features = torch.matmul(adj, h)\n",
                "            combined = torch.cat([h, neighbor_features], dim=-1)\n",
                "            h_new = layer(combined)\n",
                "            h = self.layer_norms[i](h + self.dropout(h_new))\n",
                "        \n",
                "        # Output prediction\n",
                "        output = self.output_head(h)\n",
                "        return output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# GBDT Model\n",
                "# ============================================================================\n",
                "class GBDTPredictor:\n",
                "    \"\"\"GBDT model for tabular feature prediction.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: Config):\n",
                "        self.config = config\n",
                "        self.model_x = None\n",
                "        self.model_y = None\n",
                "        self.feature_cols = None\n",
                "        self.scaler = StandardScaler()\n",
                "        \n",
                "    def prepare_features(\n",
                "        self, \n",
                "        df: pd.DataFrame, \n",
                "        feature_cols: List[str]\n",
                "    ) -> np.ndarray:\n",
                "        \"\"\"Prepare features for GBDT model.\"\"\"\n",
                "        self.feature_cols = [c for c in feature_cols if c in df.columns]\n",
                "        \n",
                "        X = df[self.feature_cols].values\n",
                "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
                "        \n",
                "        return X\n",
                "    \n",
                "    def predict(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
                "        \"\"\"Generate predictions using GBDT models.\"\"\"\n",
                "        if self.model_x is None or self.model_y is None:\n",
                "            raise ValueError(\"Models not trained. Call train() first.\")\n",
                "        \n",
                "        X = self.prepare_features(df, self.feature_cols)\n",
                "        X_scaled = self.scaler.transform(X)\n",
                "        \n",
                "        pred_x = self.model_x.predict(X_scaled)\n",
                "        pred_y = self.model_y.predict(X_scaled)\n",
                "        \n",
                "        return pred_x, pred_y\n",
                "    \n",
                "    def load(self, path: str):\n",
                "        \"\"\"Load model from disk.\"\"\"\n",
                "        with open(path, 'rb') as f:\n",
                "            data = pickle.load(f)\n",
                "            self.model_x = data['model_x']\n",
                "            self.model_y = data['model_y']\n",
                "            self.scaler = data['scaler']\n",
                "            self.feature_cols = data['feature_cols']\n",
                "        print(f\"Model loaded from {path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# Inference Logic\n",
                "# ============================================================================\n",
                "\n",
                "# Global model storage\n",
                "GLOBAL_GBDT_MODEL = None\n",
                "GLOBAL_TRANSFORMER_MODEL = None\n",
                "GLOBAL_GNN_MODEL = None\n",
                "GLOBAL_FEATURE_ENGINEER = None\n",
                "GLOBAL_CONFIG = None\n",
                "GLOBAL_INITIALIZED = False\n",
                "\n",
                "def initialize_model():\n",
                "    \"\"\"Initialize model for inference.\"\"\"\n",
                "    global GLOBAL_GBDT_MODEL, GLOBAL_TRANSFORMER_MODEL, GLOBAL_GNN_MODEL\n",
                "    global GLOBAL_FEATURE_ENGINEER, GLOBAL_CONFIG, GLOBAL_INITIALIZED\n",
                "    \n",
                "    if GLOBAL_INITIALIZED:\n",
                "        return\n",
                "    \n",
                "    GLOBAL_CONFIG = Config()\n",
                "    GLOBAL_FEATURE_ENGINEER = FootballFeatureEngineer(GLOBAL_CONFIG)\n",
                "    GLOBAL_GBDT_MODEL = GBDTPredictor(GLOBAL_CONFIG)\n",
                "    \n",
                "    # --- LOAD UNIFIED MODEL ---\n",
                "    model_path = None\n",
                "    if os.path.exists('./model_output/model.pkl'):\n",
                "        model_path = './model_output/model.pkl'\n",
                "    elif os.path.exists('/kaggle/input'):\n",
                "        for root, dirs, files in os.walk('/kaggle/input'):\n",
                "            if 'model.pkl' in files:\n",
                "                model_path = os.path.join(root, 'model.pkl')\n",
                "                break\n",
                "    \n",
                "    if model_path:\n",
                "        print(f\"Loading unified model from: {model_path}\")\n",
                "        with open(model_path, 'rb') as f:\n",
                "            data = pickle.load(f)\n",
                "            \n",
                "        # 1. Load GBDT\n",
                "        if 'gbdt_model' in data:\n",
                "            GLOBAL_GBDT_MODEL = data['gbdt_model']\n",
                "            print(\"GBDT model loaded.\")\n",
                "            \n",
                "        # 2. Load Transformer\n",
                "        input_dim = 27 # Default\n",
                "        if 'feature_cols' in data:\n",
                "             input_dim = len(data['feature_cols'])\n",
                "             \n",
                "        GLOBAL_TRANSFORMER_MODEL = PlayerMovementTransformer(\n",
                "            input_dim=input_dim,\n",
                "            d_model=GLOBAL_CONFIG.d_model,\n",
                "            n_heads=GLOBAL_CONFIG.n_heads,\n",
                "            n_encoder_layers=GLOBAL_CONFIG.n_encoder_layers\n",
                "        ).to(GLOBAL_CONFIG.device)\n",
                "        \n",
                "        if 'transformer_state_dict' in data:\n",
                "            GLOBAL_TRANSFORMER_MODEL.load_state_dict(data['transformer_state_dict'])\n",
                "            print(\"Transformer weights loaded.\")\n",
                "        GLOBAL_TRANSFORMER_MODEL.eval()\n",
                "\n",
                "        # 3. Load GNN\n",
                "        if HAS_TORCH_GEOMETRIC:\n",
                "            GLOBAL_GNN_MODEL = PlayerInteractionGNN(\n",
                "                input_dim=input_dim,\n",
                "                hidden_dim=GLOBAL_CONFIG.gnn_hidden_dim,\n",
                "                num_layers=GLOBAL_CONFIG.gnn_num_layers\n",
                "            ).to(GLOBAL_CONFIG.device)\n",
                "            \n",
                "            if 'gnn_state_dict' in data and data['gnn_state_dict'] is not None:\n",
                "                GLOBAL_GNN_MODEL.load_state_dict(data['gnn_state_dict'])\n",
                "                print(\"GNN weights loaded.\")\n",
                "            GLOBAL_GNN_MODEL.eval()\n",
                "            \n",
                "    else:\n",
                "        print(\"No unified model.pkl found. Attempting to load separate files...\")\n",
                "        # Fallback to separate files logic (omitted for brevity, assume unified)\n",
                "    \n",
                "    GLOBAL_INITIALIZED = True\n",
                "\n",
                "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n",
                "    \"\"\"\n",
                "    Main prediction function for the inference server.\n",
                "    \"\"\"\n",
                "    global GLOBAL_GBDT_MODEL, GLOBAL_TRANSFORMER_MODEL, GLOBAL_GNN_MODEL\n",
                "    global GLOBAL_FEATURE_ENGINEER, GLOBAL_CONFIG\n",
                "    \n",
                "    # Initialize on first call\n",
                "    initialize_model()\n",
                "    \n",
                "    # Convert to pandas for processing\n",
                "    test_pd = test.to_pandas() if isinstance(test, pl.DataFrame) else test\n",
                "    test_input_pd = test_input.to_pandas() if isinstance(test_input, pl.DataFrame) else test_input\n",
                "    \n",
                "    n_rows = len(test_pd)\n",
                "    \n",
                "    try:\n",
                "        # Get the last frame for each player from input (pre-pass state)\n",
                "        last_state = test_input_pd.sort_values('frame_id').groupby(\n",
                "            ['game_id', 'play_id', 'nfl_id']\n",
                "        ).last().reset_index()\n",
                "        \n",
                "        # Rename input columns\n",
                "        feature_cols = ['x', 'y', 's', 'a', 'dir', 'o']\n",
                "        rename_dict = {col: f'{col}_input' for col in feature_cols if col in last_state.columns}\n",
                "        last_state = last_state.rename(columns=rename_dict)\n",
                "        \n",
                "        # Also rename frame_id to avoid collision\n",
                "        last_state = last_state.rename(columns={'frame_id': 'last_input_frame_id'})\n",
                "        \n",
                "        # Merge test with input features\n",
                "        merged = test_pd.merge(\n",
                "            last_state,\n",
                "            on=['game_id', 'play_id', 'nfl_id'],\n",
                "            how='left'\n",
                "        )\n",
                "        \n",
                "        # Engineer features\n",
                "        merged = GLOBAL_FEATURE_ENGINEER.engineer_features(merged, is_training=False)\n",
                "        \n",
                "        # --- 1. GBDT Prediction ---\n",
                "        pred_x_gbdt = np.zeros(n_rows)\n",
                "        pred_y_gbdt = np.zeros(n_rows)\n",
                "        \n",
                "        if GLOBAL_GBDT_MODEL.model_x is not None:\n",
                "            pred_x_gbdt, pred_y_gbdt = GLOBAL_GBDT_MODEL.predict(merged)\n",
                "        else:\n",
                "            # Physics baseline if GBDT missing\n",
                "            dt = 0.1 * merged['frame_id']\n",
                "            if 's_input' in merged.columns and 'dir_input' in merged.columns:\n",
                "                vx = merged['s_input'] * np.cos(np.radians(merged['dir_input']))\n",
                "                vy = merged['s_input'] * np.sin(np.radians(merged['dir_input']))\n",
                "                pred_x_gbdt = merged['x_input'] + vx * dt\n",
                "                pred_y_gbdt = merged['y_input'] + vy * dt\n",
                "            else:\n",
                "                pred_x_gbdt = merged.get('x_input', np.zeros(n_rows) + 50).values\n",
                "                pred_y_gbdt = merged.get('y_input', np.zeros(n_rows) + 26.65).values\n",
                "\n",
                "        # --- 2. Transformer Prediction ---\n",
                "        pred_x_trans = np.zeros(n_rows)\n",
                "        pred_y_trans = np.zeros(n_rows)\n",
                "        \n",
                "        # Prepare tensor input (simplified: treating current row as sequence of length 1)\n",
                "        feature_cols = GLOBAL_FEATURE_ENGINEER.get_feature_columns()\n",
                "        valid_cols = [c for c in feature_cols if c in merged.columns]\n",
                "        X_tensor = torch.tensor(merged[valid_cols].fillna(0).values, dtype=torch.float32).to(GLOBAL_CONFIG.device)\n",
                "        X_tensor = X_tensor.unsqueeze(1) # (Batch, SeqLen=1, Features)\n",
                "        \n",
                "        if GLOBAL_TRANSFORMER_MODEL is not None:\n",
                "            with torch.no_grad():\n",
                "                if X_tensor.shape[2] == GLOBAL_TRANSFORMER_MODEL.input_proj[0].in_features:\n",
                "                    out = GLOBAL_TRANSFORMER_MODEL(X_tensor)\n",
                "                    pred_x_trans = out[:, 0].cpu().numpy()\n",
                "                    pred_y_trans = out[:, 1].cpu().numpy()\n",
                "        \n",
                "        # --- 3. GNN Prediction ---\n",
                "        pred_x_gnn = np.zeros(n_rows)\n",
                "        pred_y_gnn = np.zeros(n_rows)\n",
                "        \n",
                "        if GLOBAL_GNN_MODEL is not None and HAS_TORCH_GEOMETRIC:\n",
                "             with torch.no_grad():\n",
                "                positions = torch.stack([\n",
                "                    torch.tensor(merged['x_input'].fillna(50).values),\n",
                "                    torch.tensor(merged['y_input'].fillna(25).values)\n",
                "                ], dim=1).to(GLOBAL_CONFIG.device).unsqueeze(1)\n",
                "                \n",
                "                if X_tensor.shape[2] == GLOBAL_GNN_MODEL.input_proj.in_features:\n",
                "                     out = GLOBAL_GNN_MODEL(X_tensor.squeeze(1), positions.squeeze(1))\n",
                "                     pred_x_gnn = out[:, 0].cpu().numpy()\n",
                "                     pred_y_gnn = out[:, 1].cpu().numpy()\n",
                "\n",
                "        # --- Ensemble ---\n",
                "        w_gbdt = GLOBAL_CONFIG.gbdt_weight\n",
                "        w_trans = GLOBAL_CONFIG.transformer_weight\n",
                "        w_gnn = GLOBAL_CONFIG.gnn_weight\n",
                "        \n",
                "        total_w = w_gbdt + w_trans + w_gnn\n",
                "        w_gbdt /= total_w\n",
                "        w_trans /= total_w\n",
                "        w_gnn /= total_w\n",
                "        \n",
                "        final_pred_x = w_gbdt * pred_x_gbdt + w_trans * pred_x_trans + w_gnn * pred_x_gnn\n",
                "        final_pred_y = w_gbdt * pred_y_gbdt + w_trans * pred_y_trans + w_gnn * pred_y_gnn\n",
                "        \n",
                "        # Clip\n",
                "        final_pred_x = np.clip(final_pred_x, 0, 120)\n",
                "        final_pred_y = np.clip(final_pred_y, 0, 53.3)\n",
                "            \n",
                "    except Exception as e:\n",
                "        # Fallback predictions (field center)\n",
                "        final_pred_x = np.zeros(n_rows) + 50\n",
                "        final_pred_y = np.zeros(n_rows) + 26.65\n",
                "    \n",
                "    # Create prediction dataframe\n",
                "    predictions = pl.DataFrame({\n",
                "        'x': final_pred_x.tolist(),\n",
                "        'y': final_pred_y.tolist()\n",
                "    })\n",
                "    \n",
                "    return predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# Main Execution\n",
                "# ============================================================================\n",
                "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
                "\n",
                "def get_data_dir():\n",
                "    # Potential paths to check for test.csv\n",
                "    paths = [\n",
                "        '/kaggle/input/nfl-big-data-bowl-2026-prediction/',\n",
                "        './test/',\n",
                "        './',\n",
                "        '/kaggle/input/nfl-big-data-bowl-2026-prediction/train/'\n",
                "    ]\n",
                "    for p in paths:\n",
                "        if os.path.exists(os.path.join(p, 'test.csv')):\n",
                "            return os.path.abspath(p)\n",
                "    return None\n",
                "\n",
                "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
                "    inference_server.serve()\n",
                "else:\n",
                "    # Local testing\n",
                "    local_data_dir = get_data_dir()\n",
                "    if local_data_dir:\n",
                "        print(f\"Running local gateway with data from: {local_data_dir}\")\n",
                "        inference_server.run_local_gateway((local_data_dir,))\n",
                "    else:\n",
                "        print(\"Error: Could not find test.csv in common directories. Please check your data path.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "torch_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
